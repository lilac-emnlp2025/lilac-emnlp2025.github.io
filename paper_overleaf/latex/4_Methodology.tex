




\section{Proposed Method}


We propose \texttt{LILaC}, a novel retrieval algorithm utilizing a layered component graph and traversal method to retrieve a query-relevant subgraph. 
As shown in Figure~\ref{fig:idea_overview}, it consists of two stages: 
(i) \textbf{Layered Graph Construction} organizes multimodal documents into a layered component graph with explicit intra- and inter-document edges. 
(ii) \textbf{Late-interaction-based Subgraph Retrieval} iteratively traverses the layered graph in an edge-wise manner.
To score an edge using node-level embeddings, it uses late interaction between the decomposed subqueries and low-layer subcomponents of an edge.
















\subsection{Layered Component Graph Construction}
% 0.75페이지


In the offline phase, \texttt{LILaC} constructs a layered graph structure $\mathcal{G}$, called the \textit{layered component graph}, from the multimodal document set $\mathcal{D}$ and the associated link mapping $\mathcal{L}$.
\updated{
The graph is designed to represent \emph{relationships among components} while also allowing each component to be expressed via \emph{fine-grained constituent elements}.
It comprises two distinct layers explicitly designed to represent semantic relationships among multimodal components, offering two primary advantages.
First, the top layer supports multihop retrieval by explicitly modeling relationships between components and documents, enabling identification of relevant contexts.
Second, the lower layer facilitates precise, fine-grained reasoning by further decomposing components into finer \textit{subcomponents} (defined in Definition~\ref{def:subcomponent}), thus providing detailed context for accurate retrieval.
In addition, the edges explicitly encode two relations among these nodes: 
(i) \emph{hierarchical containment}, which links coarse components to fine-grained subcomponents; 
and (ii) \emph{navigational relations}, which preserve potential cross-component affinity (both intra- and cross-document) without prematurely committing to a specific semantic.}

% This graph comprises two distinct layers explicitly designed to represent semantic relationships among multimodal components, offering two primary advantages.
% First, the top layer supports multihop retrieval by explicitly modeling relationships between components and documents, enabling identification of relevant contexts.
% Second, the lower layer facilitates precise, fine-grained reasoning by further decomposing components into finer \textit{subcomponents}, thus providing detailed context for accurate retrieval.

\begin{definition}[\textbf{Layered Component Graph}]
\label{def:layered_component_graph}
We define a \textit{layered component graph} as $\mathcal{G} = (V, E, \lambda, \tau)$, where $V$ is a set of vertices.
A vertex $v$ belongs to one of the two layers, determined by the layer map \(\lambda : V \to \{0,1\}\), where $0$ and $1$ corresponds to the coarse-grained and fine-grained nodes, respectively.
\vspace{-3mm}
\begin{align*}
    V_0 &= V_{\text{para}}\;\cup\;V_{\text{tbl}}\;\cup\;V_{\text{img}} \\ 
    V_1 &= V_{\text{sent}}\;\cup\;V_{\text{row}}\;\cup\;V_{\text{obj}} 
    \vspace{-3mm}
\end{align*}
We denote each vertex set - \(V_{\text{para}}\): paragraphs, \(V_{\text{tbl}}\): tables, \(V_{\text{img}}\): images, \(V_{\text{sent}}\): sentences, \(V_{\text{row}}\): table rows, \(V_{\text{obj}}\): visual objects detected in images.
The type map
\(\tau : V \to
  \{\texttt{para},\texttt{tbl},\texttt{img},\texttt{sent},\texttt{row},\texttt{obj}\}
\)
refines the vertex set $V$ into the six disjoint categories.
The edge set \(E \subseteq V \times V\) is the union \(E = E_{0} \cup E_\downarrow\) where
\vspace{-3mm}
\begin{align*}
  E_0 &\;=\; \bigl\{(u,v)\in V_0^2\}              \\
  E_\downarrow &\;=\; \bigl\{(u, v)\mid u \in V_0, v \in V_1\}
  \vspace{-3mm}  
\end{align*}
\(E_0\) captures \emph{relationships} between the macro components, while \(E_\downarrow\) captures the containment of a macro component of its subcomponent.
\end{definition}

\begin{definition}[\textbf{Subcomponent}]
\label{def:subcomponent}
Let \(C\) be a multimodal component.  
A \emph{subcomponent} \(c \in \mathcal{S}(C)\) is defined in a modality-specific manner:
\squishlist
    \item \textbf{Paragraph.}  
          For a paragraph \(P = [p_1,\dots,p_{k_{sent}}]\) consisting of sentences, each sentence $p_j$ is a subcomponent.
    \item \textbf{Table.}  
          Let \(T = [T_0;T_1;\dots;T_{k_{row}}]\) where \(T_0\) is the header row.  
          For every data row \(T_i \;(1 \le i \le k_{row})\), the two-row segment $t_i = [\,T_0;\,T_i\,]$ is a subcomponent.
    \item \textbf{Image.}  
          Given an image tensor \(I \in \mathbb{R}^{w \times h \times a}\) and an object detector that
          returns a bounding box \((x_1,y_1,x_2,y_2)\), the corresponding patch
          \vspace{-3mm}
          \[
            i = I[x_1:x_2,\;y_1:y_2,\,:]
            \vspace{-3mm}
          \]
          is a subcomponent.
\squishend
\end{definition}

% Paragraph 2) Tree를 먼저 만들고, 이들끼리 link를 만들어 최종 graph를 생성한다.
Layered component graph $\mathcal{G}$ is constructed in two steps.
First, \texttt{LILaC} builds a \textit{component tree} for each component $C$ within $\mathcal{D}$.
A component tree is a two-level tree structure with the root representing the component itself and its children representing the subcomponents, which are extracted differently depending on the modality of the component.
\updated{The roots and leaves of these trees form the nodes of $V_0$ and the nodes of $V_1$, respectively, while the parent–child links correspond to the edges in $E_{\downarrow}$.}
For a paragraph $P$, \texttt{LILaC} utilizes a Sentence-aware Transformer (\texttt{SaT}) model to split it into a set of sentences.
A table $T$ is parsed to generate a set of table segments.
Lastly, a multimodal LLM is used to detect objects within $I$.
\texttt{LILaC} then generates an edge $(C, c) \in E_\downarrow$ for $c \in \mathcal{S}(C)$.

    % Paragraph 3) Component끼리의 edge를 만드는 방법
In the next step, \texttt{LILaC} generates the inter-component edges $E_0$ using both inherent structural relationships and hyperlink-based connections. 
For every document $D \in \mathcal{D}$, a clique is formed among its components:
\vspace{-3mm}
\begin{equation}
    E_{intra} = \{(C_i, C_j) | C_i \neq C_j, C_i, C_j \in D\}
    \vspace{-3mm}
\end{equation}
To enable cross-document multihop reasoning, \texttt{LILaC} then follows the link mapping $\mathcal{L}$.
For each pair $(C, D) \in \mathcal{L}$, it connects $C$ to every component in the linked document $\mathcal{D}$.
\vspace{-3mm}
\begin{equation}
    E_{inter} = \{(C, C') | (C, D) \in \mathcal{L}, C' \in D\}
    \vspace{-3mm}
\end{equation}
The inter-component edge set for the top layer is therefore $E_0 = E_{intra} \cup E_{inter}$.
Finally, every node $v \in V$ receives an embedding $\textbf{v} = f(v)$ from a pre-trained multimodal encoder $f$.











\subsection{Late-interaction-based Subgraph Retrieval}


During the online phase, \texttt{LILaC} retrieves a query-relevant subgraph $\mathcal{G}'$ from the layered component graph $\mathcal{G}$ given a query $Q$.  
This retrieval faces two key challenges: 
(1) Direct identification of an optimal subgraph from all possible candidates is computationally infeasible due to a combinatorial explosion~\cite{grag}. 
In particular, the layered component graph contains numerous edges, making explicit embedding of all edges prohibitively expensive in terms of space and computation.
(2) Queries often lack explicit modality instructions, causing ambiguity for multimodal embedders, particularly in complex multihop scenarios~\cite{uniir}.
To address these, we introduce a two-step retrieval strategy: 
(i) \textit{LLM-driven query decomposition}, which explicitly generates modality-specific subqueries, and 
(ii) \textit{Late-interaction-guided graph traversal}, a beam-search traversal method dynamically scoring edges based on fine-grained interactions within the low-level nodes.






\subsubsection{LLM-driven Query Decomposition}

Given a potentially complex query $Q$, \texttt{LILaC} first leverages an LLM to explicitly decompose $Q$ into simpler modality-specific subqueries.
Specifically, we utilize a zero-shot prompting strategy to generate a small set of subqueries:
\vspace{-2mm}
\begin{equation}
\{q_1, \dots, q_{k_{sub}}\} = \text{LLM}(Q;\, prompt_{\mathrm{dec}})
    \vspace{-2mm}
\end{equation}
Each subquery is then classified into a modality label  
$m_j\!\in\!\{\texttt{text},\texttt{table},\texttt{image}\}$ with a second prompt:
\vspace{-2mm}
\begin{equation}
m_j \;=\; \text{LLM}(q_j;\, \textit{prompt}_{\mathrm{mod}})
    \vspace{-2mm}
\end{equation}
Using these labels, we obtain modality-specific embeddings $\mathbf{q}_j = f(q_j;\, m_j)$ for every subquery, while the original query is embedded coarsely as $\mathbf{Q} = f(Q;\, \varepsilon)$ to seed the initial candidate search.  
We denote the set of embedded subqueries as $\textbf{Q}_{\text{sub}} = \{\mathbf q_1,\dots,\mathbf q_{k_{\text{sub}}}\}$.
Full prompt templates appear in \S\ref{sec:prompt_templates}.





















\subsubsection{Late-interaction-guided Graph Traversal}
\label{sec:late_interaction}

At inference time, \texttt{LILaC} searches for a subgraph $\mathcal{G}'\!\subseteq\!\mathcal{G}$ that best matches the query.  
\texttt{LILaC} maintains a beam of size $b$ and iteratively identify a candidate subgraph $\mathcal{G}_t=({V}_t,{E}_t, \lambda, \tau)$ consisting of $b$ edges.
Initially, to efficiently narrow the search space from numerous candidate nodes, \texttt{LILaC} identifies a set of top-$b$ top-level nodes $V_0$ most relevant to the query.
\begin{equation}
{V}_{0}
  = \operatorname*{arg\,max}_{C\in V_0}^{b}
    \operatorname{sim}\!\bigl(\mathbf{Q},\mathbf{C}\bigr),
\quad
{E}_{0}= \{\} 
\end{equation}


\texttt{LILaC} then initiates iterative traversal of the graph starting from these candidate nodes. 
In each iteration, \texttt{LILaC} first expands the candidate nodes via one-hop traversal to consider adjacent nodes, dynamically computing query-relevance scores for all edges formed by these expansions. 
Subsequently, only the top-$b$ scored edges are retained for the next iteration forming subgraph, and their constituent nodes become the new set of candidate nodes, forming $\mathcal{G}_i = (V_i, E_i, \lambda, \tau)$. 
After the final iteration $n_i$, \texttt{LILaC} returns the top-$n_{ret}$ nodes from the final subgraph $\mathcal{G}_{n_i}$.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{figures/late_interaction.pdf}
  \caption{An example case of edge-level late interaction.}
  \label{fig:late_interaction}
\end{figure}

\textbf{Late Interaction Edge Scoring.}
As previously discussed, naively calculating edge scores negatively impacts both effectiveness and efficiency. 
Specifically, this is because 
(1) subqueries, each potentially targeting distinct modalities, must accurately align with the relevant nodes, and 
(2) embedding all edges within the layered graph is inefficient due to their vast number.

To efficiently address these issues, \texttt{LILaC} employs a \emph{late interaction} strategy, scoring each edge on-the-fly with \emph{fine-grained} evidence.
\updated{\texttt{LILaC} extends the standard token-level late interaction to operate at the node-subquery level, by matching decomposed subqueries against the subcomponents contained within an edge.}
Let an edge be $e = (C_\alpha, C_\beta)$ and $\mathcal{S}_e = \mathcal{S}(C_\alpha) \cup \mathcal{S}(C_\beta)$.
\texttt{LILaC} gathers every subcomponent that could provide evidence on either side of the edge in the set $\mathcal{S}_e$.
\vspace{-3mm}
\begin{equation}
s(e;\textbf{Q}_{sub})
    \;=\;
    \sum_{\mathbf q\in\mathbf{Q}_{sub}}
        \max_{c\in\mathcal S_e}
        \operatorname{sim}\bigl(f(c),\mathbf q\bigr).
    \vspace{-3mm}
\label{eq:edge_score}
\end{equation}
The inner \(\max\) selects, for each sub-query \(\mathbf q\), the single most relevant sub-component \(\mathbf c\) incident to the edge, while the outer sum ensures every sub-query contributes exactly once. 
Figure~\ref{fig:late_interaction} shows two example cases of late interaction scoring.
This scoring approach is designed to reflect practical scenarios where each subquery specifically targets fine-grained details located within particular subcomponents.
By aggregating the maximum similarity scores across these detailed elements, rather than relying solely on coarse component embeddings, \texttt{LILaC} effectively prioritizes precise, subcomponent-level matches. 
This strategy enhances retrieval accuracy by focusing directly on relevant information, reducing the noise introduced by broader, less relevant contexts.



We introduce two special cases of edge scoring: 
\textit{(i) Isolated nodes.}  
If a component $C$ has no explicit neighbor, we introduce a dummy edge $(C,\varepsilon)$ so that $C$ can still be considered.
\textit{(ii) One-sided matches.}  
If an edge score $s(e;Q)$ equals the best single-node score of one endpoint, we return only that node to avoid including irrelevant neighbors.
Refer to Figure~\ref{fig:late_interaction} (b) for a specific example.
