
\vspace{-1mm}
\section{Multimodal Document Retrieval}
\vspace{-1mm}
\label{sec:probdef}

We study \emph{open-domain multimodal document retrieval} to find relevant components from a large multimodal corpus on a natural language query.
In this study, we follow the setup of graph-based retrieval approaches~\cite{1_lilac}, which have shown promising performances over existing naive approaches.

\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/preliminaries.pdf}
  \caption{
    Visualization of an example corpus $\mathcal{D}$ and its corresponding layered component graph $\mathcal{G}$.
    }
  \label{fig:preliminaries_example}
  \vspace{-6mm}
\end{figure}

\vspace{-1mm}
\subsection{Problem Setting}
\vspace{-1mm}
\noindent\textbf{Corpus and components.}
For the source of retrieval, a corpus $\mathcal{D}=$$\{D_1,$$\ldots,$$D_{k_{doc}}\}$ is a set of documents.
Each document $D_j$ includes an ordered list of multi-modal components $D_j=[C_{j,1},$ $\ldots,$ $C_{j,k_j}]$, where the global component pool is defined as $\mathcal{C}$ $=$ $\bigcup_{j=1}^{k_{doc}}\{$ $C_{j,1},$ $\ldots,$ $C_{j,k_j}\}$.
The modality of each component $C\in\mathcal{C}$ can be a paragraph $P$, a table $T$, or an image $I$ as shown in Figure~\ref{fig:preliminaries_example}.

\vspace{-1mm}
\noindent\textbf{Navigational links.}
We assume a link signal $\mathcal{L}$ capturing navigational associations (e.g., hyperlinks and cross-document pointers), modeled as $\mathcal{L}:\mathcal{C}\rightarrow\mathcal{D}$.

\vspace{-1mm}
\noindent\textbf{Multimodal retrieval task.}
Given $Q$, $\mathcal{D}$, and $\mathcal{L}$, the retriever ranks components in $\mathcal{C}$ and returns $\mathcal{C}_{R}=[C_{R_1},\ldots,C_{R_n}]$.
Let $\mathcal{C}_{gt}(Q)=\{C_{gt_1},\ldots,C_{gt_r}\}$ be the ground-truth relevant set; the goal is to rank its elements in $\mathcal{R}$, ideally near the top.


% Here, you should add some notes how previous study formulate and solve this retrieval task. 
% For example, there computes the similarity between the embedding of each component and query, but they cannot consider the structure, semantic, and context of each document. 
% Also, they are very inefficient. 
% Here, we can also add a brief note of that we formulate and solve this program as sequential action process as shown in Section 4.
% {\color{blue} 
% \noindent\textbf{Existing Approaches.}
% 기존의 방법론들은 webpage의 screenshot 별로 embedding vector 하나씩을 만들고, 한 번의 knn을 진행하는 형태로 retrieval을 진행한다~\cite{4_colpali, 3_visrag}.
% 다만 이 경우 서로 다른 component 간의 관계를 고려하기 어렵기 때문에, multihop retrieval에서 struggle한다.
% 더 최근의 연구는 navigational link를 이용하여 component를 연결해 놓고, 두 개의 pair 단위로 score를 계산하여 multihop을 해결하고자 했다.
% 이 과정에서 component를 subcomponent로 쪼개고, query 또한 subquery로 쪼갠 후에 이들 간의 fine-grained vector similarity를 비교한다.
% 하지만 이는 vector similarity에 기반하여 query-relevancy를 재기 때문에 accuracy에 한계가 있으며, 직접적으로 연결되어 있지 않은 두 component의 연관성을 파악하기에 어려움이 있다.
% }

% \jhyun{
% \noindent\textbf{Existing Approaches.}
% Early lines of work typically vision-vector-based.
% They construct a single embedding vector per webpage screenshot and perform retrieval via a one-shot $k$NN search~\cite{4_colpali, 3_visrag}.
% While efficient, this design largely ignores the relationships between components across pages and across documents, which makes multihop retrieval brittle.
% A more recent work explicitly expresses such relationships by connecting components using navigational links as edges, and attempts to solve multihop retrieval by scoring edges~\cite{1_lilac}.
% In doing so, it further splits each component into subcomponents and decomposes the query into subqueries, then compares vector similarities for the fine-grained units.
% However, it still may struggle on accurately resolving the component relationship as it relies on vector-based scores.
% Also, the static query decomposition may lead to an error propagation when done erroneously. 
% }











\vspace{-1mm}
\subsection{Layered Component Graph}
\label{sec:lcg}
\vspace{-1mm}

We incorporate a layered component graph~\cite{1_lilac} to support an effective \emph{coarse-to-fine} retrieval across documents and their components.
To efficiently retrieve relevant documents and evidence for a given query, open-domain retrieval requires to plan both which documents to visit and which components to read.
Thus, we adopt the three-layered component graph to effectively represent documents, components, subcomponents, and their complex relations.
Figure~\ref{fig:preliminaries_example} shows an example graph $\mathcal{G}$.

\vspace{-1mm}
\noindent\textbf{Nodes and Layers.}
Let $\mathcal{G}=(\mathcal{V},\mathcal{E})$ denote the graph. 
Using the definitions from Section~\ref{sec:probdef}, we construct a three-layered hierarchy $\mathcal{V} = V_0 \cup V_1 \cup V_2$:

\vspace{-2mm}
\squishlist
    \item \textit{Layer 0 (Documents) $V_0$}
    \item \textit{Layer 1 (Components) $V_1$}: paragraphs/tables/images
    \item \textit{Layer 2 (Subcomponents) $V_2$}: sentences, table rows, or visual objects
\squishend
\vspace{-2mm}
% \dylee{
For nodes in $V_1\cup V_2$, we save the raw multimodal content.
For nodes in $V_0$, we save a short textual summary of each document to avoid long inputs while preserving high-level semantics for global routing.% [DOYUP] do we need this?}

Different from LILAC~\cite{1_lilac}, which uses two layers only with components and subcomponents, we add an explicit \emph{Document Layer} to store a concise \emph{textual summary} per document node.
Adding document layer enables early pruning before descending to fine-grained evidence and can significantly improve the retrieval performance.

\vspace{-1mm}
\noindent\textbf{Hierarchical Edges.}
These edges represent the ``contains'' relationship, allowing the agent to drill down from coarse to fine granularity.
\vspace{-2mm}
\squishlist
    \item Edges $(D_j, C_{j,i})$ for all components $C_{j,i} \in D_j$.
    \item Edges linking a component to its extracted subcomponents. %(e.g., $v(T) \to v(T_{row})$).
\squishend
\vspace{-1mm}

\vspace{-1mm}
\noindent\textbf{Navigational Edges.}
These edges capture explicit navigational paths across the corpus, allowing the retriever to transition between different document contexts based on the link signal $\mathcal{L}$.
Using the link signal $\mathcal{L}$, we generate an edge $(C,D_k)$ if $\mathcal{L}(C)=D_k$.
% \vspace{-2mm}
% \squishlist
% \textit{Component$\to$Document ($V_1\!\to\!V_0$)}: 
%     \item \textit{Document$\to$Document ($V_0\!\to\!V_0$)}: if $\exists\,C\in D_j$ with $\mathcal{L}(C)=D_k$, add $(v(D_j),v(D_k))$.
% \squishend
% \vspace{-2mm}

Figure~\ref{fig:preliminaries_example} illustrates the two edge types: dotted lines express hierarchical edges, and blue lines express navigational edges.



















%%%%%%%%%%%% Version 3


% We consider the task of \emph{open-domain multimodal document retrieval}: for a natural-language query, the system returns a ranked shortlist of components drawn from a large multimodal document corpus.
% We adopt the overall setup of \textsc{LILaC}~\cite{1_lilac}.


% \noindent\textbf{Corpus, documents and components.}
% A corpus $\mathcal{D}$ $=$ $\{D_1,$ $\ldots,$ $D_{k_{doc}}\}$ consists of multimodal documents.
% Each document $D_j$ is parsed into an ordered collection of components $D_j$ $=$ $[C_{j,1},$ $\ldots,$ $C_{j,k_j}]$, and we denote the global component pool as $\mathcal{C}$ $=$ $\bigcup_{j=1}^{k_{doc}} \{C_{j,1},$ $\ldots,$ $C_{j,k_j}\}$.
% Every component $C\in\mathcal{C}$ has a modality type in $\{P,T,I\}$:
% \squishlist
%     \item \textit{Paragraph} $P$: a token sequence representing an unstructured text span.
%     \item \textit{Table} $T$: a matrix of cells (or records) with rows denoted by $T_i$.
%     \item \textit{Image} $I$: a pixel tensor $I\in\mathbb{R}^{w\times h\times a}$ with width $w$, height $h$, and channels $a$.
% \squishend
% An example corpus is given in Figure~\ref{fig:preliminaries_example}.


% \noindent\textbf{Navigational links.}
% Beyond containment within a document, we assume access to a link signal $\mathcal{L}$ that captures navigational associations commonly observed in webpages.
% Concretely, $\mathcal{L}$ connects components to documents through references such as hyperlinks and cross-document pointers, i.e.,
% $\mathcal{L}:\mathcal{C}\rightarrow \mathcal{D}$. % (and can be viewed as inducing a document/component-level navigation graph). 




% \noindent\textbf{Retrieval task.}
% Given a query $Q$, the corpus $\mathcal{D}$, and the link signal $\mathcal{L}$, the retriever produces a ranking over components. %, e.g.,
% via a scoring function $s(Q,C)$ that induces an order on $\mathcal{C}$.
% The output is the top-$n_{ret}$ list $\mathcal{R} = [\hat{C}_1,\ldots,\hat{C}_{n_{ret}}]$. % sorted by decreasing query-relevancy.
% Let $\mathcal{C}_{gt}(Q)=\{C_{gt_1},\ldots,C_{gt_r}\}$ be the set of ground-truth relevant components for $Q$.
% The goal is to place the elements of $\mathcal{C}_{gt}(Q)$ into $\mathcal{R}$, preferably at high ranks.


% Open-domain multimodal retrieval necessitates a balance between global planning (selecting documents) and local evidence gathering (reading components).
% While \textsc{LILaC}~\cite{1_lilac} facilitates multihop reasoning via a layered graph of components and subcomponents, it treats document-level context merely as metadata rather than explicit structural nodes.
% Consequently, traversal remains confined to the component layer, where the high branching factor in large corpora renders exploration and backtracking computationally expensive.
% To bridge this gap, we extend the \textsc{LILaC} formulation with an explicit \emph{Document Layer}.
% We assign each document node a concise textual \emph{summary} instead of a raw concatenation of contents, thereby preventing semantic dilution and avoiding excessive context length.
% This structure enables a \emph{coarse-to-fine} search strategy: the retriever can navigate global hops using high-level semantics and prune irrelevant branches early, descending into fine-grained component evidence only when necessary.
% An example layered component graph is shown in Figure~\ref{fig:preliminaries_example} as $\mathcal{G}$.



% \squishlist
%     \item \textit{Layer 0 (Documents) $V_0$}: The set $\{v(D_j) \mid D_j \in \mathcal{D}\}$, where each node represents a full document.
%     \item \textit{Layer 1 (Components) $V_1$}: The set $\{v(C) \mid C \in \mathcal{C}\}$, corresponding to the coarse-grained paragraphs, tables, and images.
%     \item \textit{Layer 2 (Subcomponents) $V_2$}: Fine-grained nodes representing sentences, table rows, or visual objects.
% \squishend
% Each node $v$ stores a content field $x(v)$. 
% For component and subcomponent nodes ($V_1 \cup V_2$), $x(v)$ remains the raw multimodal content. 
% However, for document nodes ($V_0$), raw concatenation of all components is often too lengthy to process effectively and efficiently. 
% Thus, we set $x(v(D_j))$ to a concise \emph{textual summary} of $D_j$. 
% This summary provides a high-level semantic overview, allowing the agent to perform global hops and decisions without processing the entire document content.



% We construct $E_{nav}$ by mapping these links to both the component and document layers:
% \squishlist
%     \item \textit{Component$\to$Document ($V_1 \to V_0$)}: 
%     If a component $C \in V_1$ references a target document $D_{k}$ (i.e., $\mathcal{L}(C) = D_{k}$), we add an edge $(v(C), v(D_{k}))$. 
%     % This allows the agent to follow a specific hyperlink but forces it to land on the target's summary node first, enabling a high-level relevance check before descending into details.
    
%     \item \textit{Document$\to$Document ($V_0 \to V_0$)}: 
%     We also project navigational links to the document layer to support coarse-level planning.
%     For any two documents $D_{j}$ and $D_{k}$, if there exists any component $C$ inside $D_{j}$ that links to $D_{k}$ (i.e., $C \in D_{j} \land \mathcal{L}(C) = D_{k}$), we add a directed edge $(v(D_{j}), v(D_{k}))$.
%     % This creates a ``macro'' navigation graph, allowing the agent to jump directly between related documents without traversing intermediate component nodes.
% \squishend
% These edges are expressed in Figure~\ref{fig:preliminaries_example} as dotted lines.






%%%%%%%%%%%%%%%%%%%%%% Version 2





% Open-domain multimodal retrieval in large corpora often requires multihop navigation: the system must decide \emph{which documents to visit} (global planning) and then \emph{which components to read} (local evidence gathering).
% \textsc{LILaC}~\cite{1_lilac} addresses multihop reasoning by building a layered component graph over components and their fine-grained subcomponents, and emphasizes component-level hops via intra-/inter-document component edges.
% However, its traversal still effectively \emph{starts from} (and is dominated by) the component layer: when the corpus is vast, the branching factor at the component level can make exploration and backtracking expensive.
% Moreover, while document-level signals (e.g., document title) can be attached as metadata to components, \textsc{LILaC} does not explicitly model documents as graph nodes nor introduce document-level navigation edges.
% To enable a coarse-to-fine search strategy, we extend the \textsc{LILaC} formulation with an explicit \emph{document layer}.
% Each document node stores a short textual \emph{summary} rather than concatenating all component contents, since a document may contain many long components and a raw aggregation is often prohibitively lengthy and semantically diluted.
% This document-level abstraction allows the retriever to make global hops guided by high-level semantics, prune irrelevant branches early, and then descend to component/subcomponent evidence only when needed.

% Real-world multimodal corpora are not a flat set of independent chunks. 
% Within a document, the meaning of a component (paragraph, table, or image) is shaped by local context of surrounding components. 
% Across documents, components are connected by explicit navigational signals, including hyperlinks. 
% % A flat index discards these structural cues, making multihop evidence discovery brittle. 
% To address this, we represent the corpus as a \emph{layered component graph} that exposes a coarse-to-fine hierarchy.

% While \textsc{LILaC}~\cite{1_lilac} previously introduced a layered graph to model components and subcomponents, it focused primarily on component-level traversal; document-level information (e.g., titles) was treated merely as metadata labels attached to component nodes. 
% We argue that this is insufficient for open-domain traversal, where an agent must efficiently prune vast search spaces. 
% Therefore, we extend the \textsc{LILaC} formulation by introducing an explicit \textbf{Document Layer} ($V_0$). 
% This allows the system to assess document relevance via summaries before expending resources on specific components.



% \noindent\textbf{Navigation Edges ($E_{nav}$).}
% We unify all lateral and cross-reference connections into a single set of navigation edges $E_{nav}$, enabling both local context flow and global jumps.
% \squishlist
%     \item \textit{Local Context (Intra-document)}: 
%     To capture the flow within a document $D_j$, we add edges between adjacent or co-occurring components in $V_1$. 
%     For example, $(v(C_{j,i}), v(C_{j,i+1})) \in E_{nav}$ allows the agent to ``read around'' to neighboring paragraphs or images without leaving the current document context.
    
%     \item \textit{Global Links (Cross-document)}: 
%     We incorporate the link signal $\mathcal{L}$. 
%     If a component $C \in V_1$ references a target document $D_{k}$ (i.e., $\mathcal{L}(C) = D_{k}$), we add an edge $(v(C), v(D_{k})) \in E_{nav}$. 
%     Unlike component-to-component links, this routes navigation through the target's Layer 0 summary node. 
%     This forces the agent to evaluate the target document's high-level relevance before descending into its details, facilitating efficient pruning.
% \squishend



% % ChatGPT
% \subsection{Layered Component Graph}
% \label{sec:lcg}

% Real-world multimodal corpora are not a flat set of independent chunks. Within a document, the meaning of a
% component (paragraph/table/image) is shaped by local context (captions, surrounding text, section adjacency),
% and across documents, components are connected by explicit navigation signals (hyperlinks, citations, cross-references).
% A flat index discards these structural cues, making multihop evidence discovery brittle. We therefore represent the corpus
% as a \emph{layered component graph} that (i) preserves navigational relations for multihop traversal and (ii) exposes a
% coarse-to-fine containment hierarchy for efficient hopping and precise evidence extraction.

% We follow the layered construction of \textsc{LILaC}~\cite{1_lilac} and introduce a lightweight extension that adds an explicit
% \emph{document layer} to enable coarse, semantics-guided jumps via document summaries.

% \noindent\textbf{Graph, layers, and node contents.}
% Let $D=\{D_j\}_{j=1}^{k_{\text{doc}}}$ be the corpus, where each document $D_j=[C_{j,1},\ldots,C_{j,k_j}]$ is an ordered list of
% components, and let $\mathcal{C}=\bigcup_{j=1}^{k_{\text{doc}}}\{C_{j,1},\ldots,C_{j,k_j}\}$ denote the global component pool.
% We assume a link signal $L:\mathcal{C}\rightarrow D$ capturing cross-document pointers (e.g., hyperlinks).

% We define an \emph{extended layered component graph} as
% $G=(V,E,\lambda,\tau)$, where $\lambda$ is a layer map and $\tau$ is a type map.
% We use three layers: a document layer, a coarse component layer, and a fine-grained subcomponent layer:
% \squishlist
%     \item \textit{Document nodes} $V_D=\{v^D_j\}_{j=1}^{k_{\text{doc}}}$, where each $v^D_j$ corresponds to $D_j$.
%     \item \textit{Coarse component nodes} $V_0 = V_{\text{para}}\cup V_{\text{tbl}}\cup V_{\text{img}}$, where each node $v(C)\in V_0$
%           corresponds to a top-level component $C\in\mathcal{C}$ (paragraph/table/image).
%     \item \textit{Fine subcomponent nodes} $V_1 = V_{\text{sent}}\cup V_{\text{row}}\cup V_{\text{obj}}$, where each node $v(c)\in V_1$
%           corresponds to a subcomponent $c\in S(C)$ (sentence/row/object), as available.
% \squishend
% The full node set is $V = V_D \cup V_0 \cup V_1$.
% We set the layer map $\lambda:V\rightarrow\{-1,0,1\}$ by $\lambda(v)=-1$ for $v\in V_D$, $\lambda(v)=0$ for $v\in V_0$, and
% $\lambda(v)=1$ for $v\in V_1$. The type map is $\tau:V\rightarrow\{\text{doc},\text{para},\text{tbl},\text{img},\text{sent},\text{row},\text{obj}\}$.

% Each node $v$ stores a content field $x(v)$ used for retrieval and reasoning.
% For $v^D_j$, we set $x(v^D_j)$ to a concise textual \emph{summary} of $D_j$ (e.g., generated offline), so that document-level hops
% are guided by high-level semantics. For coarse component nodes $v(C)\in V_0$, $x(v(C))$ is the component content.
% For fine nodes $v(c)\in V_1$, $x(v(c))$ is the corresponding subcomponent content.

% \noindent\textbf{Containment edges.}
% We add directed containment edges that encode the document$\rightarrow$component$\rightarrow$subcomponent hierarchy:
% \squishlist
%     \item \textit{Document$\rightarrow$component}: $E_{D\downarrow}=\{(v^D_j, v(C_{j,i})) \mid C_{j,i}\in D_j\}$.
%     \item \textit{Component$\rightarrow$subcomponent}: $E_{\downarrow}=\{(v(C), v(c)) \mid c\in S(C)\}$.
% \squishend

% \noindent\textbf{Inter-component edges (coarse layer).}
% Following \textsc{LILaC}~\cite{1_lilac}, we encode navigational relations among coarse components with
% $E_0 = E_{\text{intra}} \cup E_{\text{inter}} \subseteq V_0\times V_0$:
% \begin{align}
% E_{\text{intra}} &= \{(v(C_i), v(C_j)) \mid C_i \neq C_j,\; C_i,C_j \in D_j \}, \label{eq:eintra}\\
% E_{\text{inter}} &= \{(v(C), v(C')) \mid L(C)=D_{j'},\; C'\in D_{j'} \}. \label{eq:einter}
% \end{align}
% $E_{\text{intra}}$ captures within-document co-occurrence/proximity, while $E_{\text{inter}}$ preserves cross-document navigation by
% connecting a linking component to the components of the linked document.

% \noindent\textbf{Document-level navigation edges (our extension).}
% We lift the same link signal $L$ to the document layer to enable coarse global jumps before descending to components:
% \squishlist
%     \item \textit{Component$\rightarrow$document}: $E_{C\rightarrow D}=\{(v(C), v^D_{j'}) \mid L(C)=D_{j'}\}$.
%     \item \textit{Document$\rightarrow$document}: $E_{D\rightarrow D}=\{(v^D_j, v^D_{j'}) \mid \exists\, C\in D_j \text{ s.t. } L(C)=D_{j'}\}$.
% \squishend

% \noindent\textbf{Edge set and neighborhood.}
% The full edge set is
% $E = E_0 \cup E_{\downarrow} \cup E_{D\downarrow} \cup E_{C\rightarrow D} \cup E_{D\rightarrow D}$.
% We write $N(v)=\{u \mid (v,u)\in E\}$ for outgoing neighbors.
% This unified view allows retrieval to alternate between (i) document-level jumps guided by summaries,
% (ii) coarse-layer local hops via $E_0$, and (iii) fine-grained evidence extraction via $E_{\downarrow}$.



















%%%%%%%%%%%%%%%%% Version  1

% \new{

% \subsection{Layered Component Graph}
% \label{sec:lcg}

% We represent the corpus as a \emph{layered component graph} that makes both intra-document structure
% and cross-document navigation explicit. We follow the layered construction of \textsc{LILaC}~\cite{1_lilac},
% and introduce a lightweight extension that adds an explicit \emph{document layer}.

% \noindent\textbf{Nodes and layers.}
% Let $\mathcal{G}=(\mathcal{V},\mathcal{E})$ denote the graph.
% We define two primary node types:
% \squishlist
%     \item \textit{Document nodes} $\mathcal{V}_D=\{v^D_j\}_{j=1}^{k_{doc}}$, where each $v^D_j$ corresponds to a document $D_j$.
%     \item \textit{Component nodes} $\mathcal{V}_C=\{v(C): C\in\mathcal{C}\}$, where each $v(C)$ corresponds to a component $C$.
% \squishend
% Each node $v$ stores a content field $x(v)$ used for retrieval and reasoning.
% For $v^D_j$, we set $x(v^D_j)$ to a concise textual \emph{summary} of $D_j$ (e.g., generated offline),
% so that document-level hops can be guided by high-level semantics rather than raw component text.
% For component nodes $v(C)$, $x(v(C))$ is the component content (paragraph/table/image).

% Optionally, a component can be further decomposed into finer-grained subcomponents (e.g., sentences,
% table regions/rows, or image regions), yielding additional layers.
% We denote the full node set as $\mathcal{V}=\mathcal{V}_D \cup \mathcal{V}_C \cup \mathcal{V}_{\text{sub}}$,
% where $\mathcal{V}_{\text{sub}}$ contains subcomponent nodes when available.
% (The document layer itself can also be hierarchical, e.g., page$\rightarrow$section$\rightarrow$subsection;
% our formulation naturally extends by adding more document-layer levels.)

% \noindent\textbf{Hierarchical (containment) edges.}
% We add directed containment edges from documents to their top-level components:
% $(v^D_j, v(C_{j,i}))\in\mathcal{E}$ for all $C_{j,i}\in D_j$.
% If subcomponents exist, we also add edges from a component to its subcomponents.

% \noindent\textbf{Intra-document edges.}
% To capture local context within a document, we connect top-level component nodes that co-occur within
% the same document (e.g., adjacency or section-level proximity). Concretely, for each $D_j$ we add
% edges among $\{v(C_{j,1}),\ldots,v(C_{j,k_j})\}$ to enable local hops that exploit within-document context.

% \noindent\textbf{Navigation edges (cross-document).}
% We incorporate the link signal $\mathcal{L}:\mathcal{C}\rightarrow\mathcal{D}$ (hyperlinks, cross-document pointers).
% For a link from a component $C\in D_j$ to a target document $D_{j'}$ (i.e., $\mathcal{L}(C)=D_{j'}$), we add:
% \squishlist
%     \item \textit{Component$\rightarrow$document}: $(v(C), v^D_{j'})\in\mathcal{E}$.
%     \item \textit{Document$\rightarrow$document}: $(v^D_{j}, v^D_{j'})\in\mathcal{E}$.
% \squishend
% Thus, any cross-document pointer emitted by a component induces a document-level navigation edge,
% allowing the retriever to move between documents at a coarse level before descending to components.

% \noindent\textbf{Neighborhood.}
% We write $\mathcal{N}(v)=\{u\mid (v,u)\in\mathcal{E}\}$ for outgoing neighbors.
% This unified graph view allows retrieval to alternate between (i) global document-level jumps guided by summaries,
% (ii) local hops via $\mathcal{N}(\cdot)$, and (iii) component-level evidence extraction.

% }




% LILaC에서의 layered component graph를 바탕으로 간단히 서술하고, 
% 우리가 이를 extend하여서 document layer를 추가하고, 해당 node 내에는 document에 대한 summary를 기재하도록 하였다고 할 것.
% Document layer 간에서도 layer가 있을 수 있고, A라는 document에서 a라는 child component에서 B라는 document로의 edge (i.e., hyperlink)가 존재하면 A에서 B node로의 edge를 생성하였다고 할 것 (A, a, B로 설명하지 말고 식으로 설명)